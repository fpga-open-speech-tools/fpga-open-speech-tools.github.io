<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="styling/master.css">
    <link rel="stylesheet" href="styling/audio_mini.css">

    <title>Audio Mini</title>
  </head>
  <body>    
    <!-- Navigation Bar-->  
    <header> 
        <!-- Navigation Bar--> 
        <nav class="navbar navbar-expand-lg navbar-light bg-light shadow fixed-top">
            <a class="navbar-brand" href="/">FPGA Open Speech Tools</a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                    </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="#">Getting Started</a>
                    </li>  
                    <li class="nav-item">
                        <a class="nav-link" href='https://github.com/fpga-open-speech-tools/docs'>Documentation</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="https://spectrum.chat/fe-open-speech">Forum</a>
                    </li>
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                            Products
                        </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                            <a class="dropdown-item" href="audio_mini.html">Audio Mini</a>
                            <a class="dropdown-item" href="audio_blade.html">Audio Blade</a>
                        </div>
                    </li>
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                            Tools
                        </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                            <a class="dropdown-item" href="#">Open Speech Auto Gen</a>
                            <a class="dropdown-item" href="#">Open Speech Control App</a>
                        </div>
                    </li>
                </ul>
            </div>
        </nav>
    </header>

    <main>
        <div class="jumbotron jumbotron-fluid">
            <h1 class="display-2">Open Speech</h1>
            <h2 class="display-2">Audio Mini</h2>
        </div>

        <!-- Overview -->
        <div class="container">
            <h2 class="display-3">Overview</h2>
            <p>
                The Audio Mini is an audio processing cape designed for the Altera DE-10 Nano. This cape contains an AD1939 audio codec that is used to sample audio from the line input and play back audio to the headphone output. The sampled audio is passed to a Cyclone V FPGA on the DE-10 Nano where the data can be processed. This platform is ideally suited for educational use as it is relatively low-cost and can be used in conjunction with Mathworks Simulink and FPGA Open Speech Toolsâ€™ code generation tool to rapidly create effects. This workflow also makes the Audio Mini an excellent tool for developers who wish to create prototype algorithms for devices such as hearing aids or sound effects processors.
            </p>
        </div>

        <!-- Tech specs -->
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-8">
                    <h2 class="display-3"> Technical Specifications</h2>
                    <ul>
                        <li>Intel Cyclone V</li>
                        <li>3.5mm Line In Audio Interface</li>
                        <li>3.5mm Headphone Out Audio Interface</li>
                        <li>AD1939 Audio Codec</li>
                    </ul>
                </div>
                <div class="col-4">
                    <img alt='Audio Mini Rendering' src='media/audio_mini/Audio_Mini_Rev1_0.png' style="height: 500px"/>
                </div>
            </div>
        </div>

        <!-- Demos -->
        <div class="container">
            <h2 class="display-2">Demos</h2>
            <h4 class="display-4">Passthrough</h4>
            <p>
                The pass through project is the reference design for all Audio Mini projects.  Audio is simply passed from the line input to the headphone output of the Audio Mini without any added effects.  
            </p>
            <h4 class="display-4">Multi-Effects Processor</h4>
            <p>
                The multi-effects processor is a project that contains three distinct sound effects; a bitcrusher that truncates the digital audio sample word, a flanger that mixes a phase shifted copy of an audio signal with the original, and an echo.  These sound effects are controlled through an Android app running on a tablet on the same local area network.  The app contains different types of controls to alter the sound effect parameters, including switches and radial dials, which communicate to the sound effect registers in the FPGA fabric through kernel modules running on the FPGA hard processor system.
            </p>
            <h4 class="display-4">Simple Hearing Aid</h4>
            <p>
                This project is a demonstration of a very simple hearing aid that can be modified by an application running on another device.  The hearing aid is made up of two channels, each containing a master volume and four bandpass filters implemented in the FPGA fabric.  These elements are controlled through loadable kernel modules from Linux running on the hard processor system of the FPGA.
            </p>
        </div>
    </main>

    <footer class="py-4 bg-light">
        <div class="container text-center">
            <medium>Flat Earth Inc - Open Speech Tools</medium>
        </div>
    </footer>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    
  </body>
</html>